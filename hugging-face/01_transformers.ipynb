{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Working w/ pipelines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-04 16:22:58.265384: I external/local_tsl/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-03-04 16:22:58.295098: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-03-04 16:22:58.295121: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-03-04 16:22:58.296170: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-03-04 16:22:58.301357: I external/local_tsl/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-03-04 16:22:58.301829: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-03-04 16:22:59.099440: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "No model was supplied, defaulted to distilbert/distilbert-base-uncased-finetuned-sst-2-english and revision af0f99b (https://huggingface.co/distilbert/distilbert-base-uncased-finetuned-sst-2-english).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n",
      "model.safetensors: 100%|██████████| 268M/268M [00:03<00:00, 88.0MB/s] \n",
      "2024-03-04 16:23:04.998655: W external/local_tsl/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 93763584 exceeds 10% of free system memory.\n",
      "2024-03-04 16:23:05.389967: W external/local_tsl/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 93763584 exceeds 10% of free system memory.\n",
      "2024-03-04 16:23:05.448949: W external/local_tsl/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 93763584 exceeds 10% of free system memory.\n",
      "2024-03-04 16:23:06.541645: W external/local_tsl/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 93763584 exceeds 10% of free system memory.\n",
      "All PyTorch model weights were used when initializing TFDistilBertForSequenceClassification.\n",
      "\n",
      "All the weights of TFDistilBertForSequenceClassification were initialized from the PyTorch model.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFDistilBertForSequenceClassification for predictions without further training.\n",
      "tokenizer_config.json: 100%|██████████| 48.0/48.0 [00:00<00:00, 173kB/s]\n",
      "vocab.txt: 100%|██████████| 232k/232k [00:00<00:00, 1.37MB/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'label': 'POSITIVE', 'score': 0.8458861112594604}]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "classifier = pipeline(\"sentiment-analysis\")\n",
    "classifier(\"I've been waiting for a HuggingFace counrce my whole life.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'label': 'POSITIVE', 'score': 0.9598047137260437},\n",
       " {'label': 'NEGATIVE', 'score': 0.9994558691978455}]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier([\n",
    "    \"I've been waiting for a HuggingFace course my whole life.\",\n",
    "    \"I hate this so much!\"\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Zero-shot classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to FacebookAI/roberta-large-mnli and revision 130fb28 (https://huggingface.co/FacebookAI/roberta-large-mnli).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n",
      "config.json: 100%|██████████| 688/688 [00:00<00:00, 2.41MB/s]\n",
      "model.safetensors: 100%|██████████| 1.43G/1.43G [01:08<00:00, 20.9MB/s]\n",
      "2024-03-04 16:56:57.813660: W external/local_tsl/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 205885440 exceeds 10% of free system memory.\n",
      "All PyTorch model weights were used when initializing TFRobertaForSequenceClassification.\n",
      "\n",
      "All the weights of TFRobertaForSequenceClassification were initialized from the PyTorch model.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFRobertaForSequenceClassification for predictions without further training.\n",
      "tokenizer_config.json: 100%|██████████| 25.0/25.0 [00:00<00:00, 151kB/s]\n",
      "vocab.json: 100%|██████████| 899k/899k [00:00<00:00, 1.35MB/s]\n",
      "merges.txt: 100%|██████████| 456k/456k [00:00<00:00, 1.37MB/s]\n",
      "tokenizer.json: 100%|██████████| 1.36M/1.36M [00:00<00:00, 4.06MB/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'sequence': 'This is a counrse about the Transformer library',\n",
       " 'labels': ['education', 'business', 'politics'],\n",
       " 'scores': [0.48972809314727783, 0.3369224965572357, 0.17334936559200287]}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier = pipeline(\"zero-shot-classification\")\n",
    "classifier(\n",
    "   \"This is a counrse about the Transformer library\",\n",
    "   candidate_labels=[\"education\", \"politics\", \"business\"] \n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Text generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to openai-community/gpt2 and revision 6c0e608 (https://huggingface.co/openai-community/gpt2).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n",
      "config.json: 100%|██████████| 665/665 [00:00<00:00, 3.98MB/s]\n",
      "model.safetensors: 100%|██████████| 548M/548M [00:04<00:00, 134MB/s] \n",
      "All PyTorch model weights were used when initializing TFGPT2LMHeadModel.\n",
      "\n",
      "All the weights of TFGPT2LMHeadModel were initialized from the PyTorch model.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFGPT2LMHeadModel for predictions without further training.\n",
      "tokenizer_config.json: 100%|██████████| 26.0/26.0 [00:00<00:00, 18.7kB/s]\n",
      "vocab.json: 100%|██████████| 1.04M/1.04M [00:00<00:00, 3.15MB/s]\n",
      "merges.txt: 100%|██████████| 456k/456k [00:00<00:00, 922kB/s]\n",
      "tokenizer.json: 100%|██████████| 1.36M/1.36M [00:00<00:00, 7.97MB/s]\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'generated_text': 'In this cource, we will teach you how to be very careful. After my death, and during my life in jail, it was only to help people at our service. It may not have taken to much to save lives, but I knew'}]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generator = pipeline(\"text-generation\")\n",
    "generator(\"In this cource, we will teach you how to\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using any model from the Hub in a pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "config.json: 100%|██████████| 762/762 [00:00<00:00, 3.99MB/s]\n",
      "model.safetensors: 100%|██████████| 353M/353M [00:20<00:00, 16.9MB/s] \n",
      "All PyTorch model weights were used when initializing TFGPT2LMHeadModel.\n",
      "\n",
      "All the weights of TFGPT2LMHeadModel were initialized from the PyTorch model.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFGPT2LMHeadModel for predictions without further training.\n",
      "tokenizer_config.json: 100%|██████████| 26.0/26.0 [00:00<00:00, 131kB/s]\n",
      "vocab.json: 100%|██████████| 1.04M/1.04M [00:00<00:00, 1.58MB/s]\n",
      "merges.txt: 100%|██████████| 456k/456k [00:00<00:00, 7.43MB/s]\n",
      "tokenizer.json: 100%|██████████| 1.36M/1.36M [00:00<00:00, 7.64MB/s]\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'generated_text': 'In this course, we will teach you how to make a successful decision. This course teaches you how to identify and motivate and motivate more students to become'},\n",
       " {'generated_text': 'In this course, we will teach you how to use two kinds of tools:\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n'}]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generator = pipeline(\"text-generation\", model=\"distilgpt2\")\n",
    "generator(\n",
    "    \"In this course, we will teach you how to\",\n",
    "    max_length=30,\n",
    "    num_return_sequences=2\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mask filling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to distilbert/distilroberta-base and revision ec58a5b (https://huggingface.co/distilbert/distilroberta-base).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n",
      "config.json: 100%|██████████| 480/480 [00:00<00:00, 2.60MB/s]\n",
      "model.safetensors: 100%|██████████| 331M/331M [00:03<00:00, 94.9MB/s] \n",
      "All PyTorch model weights were used when initializing TFRobertaForMaskedLM.\n",
      "\n",
      "All the weights of TFRobertaForMaskedLM were initialized from the PyTorch model.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFRobertaForMaskedLM for predictions without further training.\n",
      "tokenizer_config.json: 100%|██████████| 25.0/25.0 [00:00<00:00, 155kB/s]\n",
      "vocab.json: 100%|██████████| 899k/899k [00:00<00:00, 1.36MB/s]\n",
      "merges.txt: 100%|██████████| 456k/456k [00:00<00:00, 105MB/s]\n",
      "tokenizer.json: 100%|██████████| 1.36M/1.36M [00:00<00:00, 7.85MB/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'score': 0.20977766811847687,\n",
       "  'token': 30412,\n",
       "  'token_str': ' mathematical',\n",
       "  'sequence': 'This course will teach you about mathematical models'},\n",
       " {'score': 0.05309794843196869,\n",
       "  'token': 27930,\n",
       "  'token_str': ' predictive',\n",
       "  'sequence': 'This course will teach you about predictive models'}]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unmasker = pipeline(\"fill-mask\")\n",
    "unmasker(\"This course will teach you about <mask> models\", top_k=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Named entity recognition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to dbmdz/bert-large-cased-finetuned-conll03-english and revision f2482bf (https://huggingface.co/dbmdz/bert-large-cased-finetuned-conll03-english).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n",
      "config.json: 100%|██████████| 998/998 [00:00<00:00, 5.84MB/s]\n",
      "model.safetensors: 100%|██████████| 1.33G/1.33G [01:02<00:00, 21.5MB/s]\n",
      "All PyTorch model weights were used when initializing TFBertForTokenClassification.\n",
      "\n",
      "All the weights of TFBertForTokenClassification were initialized from the PyTorch model.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertForTokenClassification for predictions without further training.\n",
      "tokenizer_config.json: 100%|██████████| 60.0/60.0 [00:00<00:00, 275kB/s]\n",
      "vocab.txt: 100%|██████████| 213k/213k [00:00<00:00, 1.27MB/s]\n",
      "/home/shukawam/work/notebooks/.venv/lib/python3.11/site-packages/transformers/pipelines/token_classification.py:168: UserWarning: `grouped_entities` is deprecated and will be removed in version v5.0.0, defaulted to `aggregation_strategy=\"AggregationStrategy.SIMPLE\"` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'entity_group': 'PER',\n",
       "  'score': 0.9986171,\n",
       "  'word': 'Sylvain',\n",
       "  'start': 11,\n",
       "  'end': 18},\n",
       " {'entity_group': 'ORG',\n",
       "  'score': 0.9777994,\n",
       "  'word': 'Hugging Face',\n",
       "  'start': 33,\n",
       "  'end': 45},\n",
       " {'entity_group': 'LOC',\n",
       "  'score': 0.9889684,\n",
       "  'word': 'Brooklyn',\n",
       "  'start': 49,\n",
       "  'end': 57}]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ner = pipeline(\"ner\", grouped_entities=True)\n",
    "ner(\"My name is Sylvain and I work at Hugging Face in Brooklyn\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question answering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to distilbert/distilbert-base-cased-distilled-squad and revision 626af31 (https://huggingface.co/distilbert/distilbert-base-cased-distilled-squad).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n",
      "config.json: 100%|██████████| 473/473 [00:00<00:00, 2.25MB/s]\n",
      "model.safetensors: 100%|██████████| 261M/261M [00:12<00:00, 20.6MB/s] \n",
      "All PyTorch model weights were used when initializing TFDistilBertForQuestionAnswering.\n",
      "\n",
      "All the weights of TFDistilBertForQuestionAnswering were initialized from the PyTorch model.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFDistilBertForQuestionAnswering for predictions without further training.\n",
      "tokenizer_config.json: 100%|██████████| 29.0/29.0 [00:00<00:00, 149kB/s]\n",
      "vocab.txt: 100%|██████████| 213k/213k [00:00<00:00, 642kB/s]\n",
      "tokenizer.json: 100%|██████████| 436k/436k [00:00<00:00, 2.61MB/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'score': 0.6949760317802429, 'start': 33, 'end': 45, 'answer': 'Hugging Face'}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question_answer = pipeline(\"question-answering\")\n",
    "question_answer(\n",
    "    question=\"Where do I work?\",\n",
    "    context=\"My name is Sylvain and I work at Hugging Face in Brooklyn\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summarization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
